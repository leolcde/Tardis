{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center;\"><u>__EDA - Exploratory Data Analysis__<u></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **🧰 Dependencies**\n",
    "\n",
    " `import pandas as pd`\n",
    "Imports the **pandas** library, a powerful tool for data manipulation and analysis using DataFrames.\n",
    "\n",
    " `import numpy as np`\n",
    "Imports **NumPy**, a fundamental library for numerical computing in Python — often used for handling arrays, math operations, and missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚄 SNCF Data Cleaner - Railway Data Cleaning Toolkit 🧹\n",
    "\n",
    "*Your all-in-one solution for cleaning and preprocessing French railway data with style and precision.*\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Overview\n",
    "\n",
    "This module offers a robust set of specialized functions to clean and prepare operational data from the French national railway system (SNCF). From removing duplicates to correcting \n",
    "station names, it’s built to address real-world data quality issues commonly found in transportation datasets.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Core Functions\n",
    "\n",
    "### 🧽 Basic Cleaning\n",
    "\n",
    "| Function                                | Description                                                                         |\n",
    "| --------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "| `remove_duplicates(df)`                 | Removes duplicate rows — because a train can't be in two places at once!            |\n",
    "| `remove_negative(df)`                   | Filters out impossible negative values from key metrics (e.g., -3 cancelled trains) |\n",
    "| `fill_missed_value(df)`                 | Smart imputation: uses median for numeric columns and preserves NaNs for text       |\n",
    "| `missing_mandatory(df, mandatory_cols)` | Drops rows with missing or invalid values in critical fields                        |\n",
    "\n",
    "### 📅 Date Handling\n",
    "\n",
    "| Function              | Description                                               |\n",
    "| --------------------- | --------------------------------------------------------- |\n",
    "| `date_formatting(df)` | Converts and standardizes all dates to `'YYYY-MM'` format |\n",
    "\n",
    "### 🏷️ Station and Service Name Correction\n",
    "\n",
    "| Function                                                                                 | Description                                                                                                       |\n",
    "| ---------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
    "| `correct_text_columns(df, station_columns, service_columns, station_list, service_list)` | Uses fuzzy matching (Levenshtein distance) to fix typos in station and service names, with caching for efficiency |\n",
    "#\n",
    "---\n",
    "\n",
    "## 🛠 Technical Details\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* Custom implementation of the Levenshtein distance for flexible fuzzy matching\n",
    "* Caching system to speed up repeated corrections\n",
    "* Configurable similarity thresholds (default: 0.7)\n",
    "\n",
    "**Predefined Station Names:**\n",
    "Includes over 50 French and international stations, such as:\n",
    "\n",
    "* **Major hubs**: Paris Montparnasse, Lyon Part-Dieu, Marseille St Charles\n",
    "* **Cross-border links**: Geneva, Barcelona, Zurich\n",
    "* **Regional stops**: Quimper, Tours, Angoulême\n",
    "\n",
    "**Service Types:**\n",
    "\n",
    "* `National`\n",
    "* `International`\n",
    "#\n",
    "---\n",
    "#\n",
    "## ⚙️ Dependencies\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct_stations = [\n",
    "    \"BORDEAUX ST JEAN\", \"LA ROCHELLE VILLE\", \"PARIS MONTPARNASSE\", \"QUIMPER\", \"TOURS\",\n",
    "    \"ST PIERRE DES CORPS\", \"ST MALO\", \"NANTES\", \"PARIS EST\", \"STRASBOURG\", \"DUNKERQUE\",\n",
    "    \"LILLE\", \"PARIS VAUGIRARD\", \"RENNES\", \"TOURCOING\", \"CHAMBERY CHALLES LES EAUX\",\n",
    "    \"LYON PART DIEU\", \"MONTPELLIER\", \"MULHOUSE VILLE\", \"NICE VILLE\", \"PARIS LYON\",\n",
    "    \"BARCELONA\", \"GENEVE\", \"MADRID\", \"BREST\", \"POITIERS\", \"TOULOUSE MATABIAU\",\n",
    "    \"MARNE LA VALLEE\", \"MARSEILLE ST CHARLES\", \"FRANCFORT\", \"ANGOULEME\", \"METZ\",\n",
    "    \"PARIS NORD\", \"BELLEGARDE (AIN)\", \"MACON LOCHE\", \"PERPIGNAN\", \"DOUAI\",\n",
    "    \"VALENCE ALIXAN TGV\", \"LAUSANNE\", \"ANGERS SAINT LAUD\", \"STUTTGART\", \"LAVAL\",\n",
    "    \"NANCY\", \"BESANCON FRANCHE COMTE TGV\", \"GRENOBLE\", \"NIMES\", \"SAINT ETIENNE CHATEAUCREUX\",\n",
    "    \"ITALIE\", \"ZURICH\", \"VANNES\", \"ANNECY\", \"AVIGNON TGV\", \"LE MANS\", \"ARRAS\",\n",
    "    \"DIJON VILLE\", \"LE CREUSOT MONTCEAU MONTCHANIN\", \"REIMS\"\n",
    "]\n",
    "\n",
    "correct_services = [\"National\", \"International\"]\n",
    "\n",
    "mandatory_cols = [\"Date\", \"Service\", \"Departure station\", \"Arrival station\"]\n",
    "\n",
    "station_cols = [\"Departure station\", \"Arrival station\"]\n",
    "\n",
    "service_cols = [\"Service\"]\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop_duplicates(subset=mandatory_cols, keep='first')\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def remove_negative(df):\n",
    "    cols_num = [\n",
    "        'Average journey time',\n",
    "        'Number of scheduled trains',\n",
    "        'Number of cancelled trains',\n",
    "        'Number of trains delayed at departure',\n",
    "        'Number of trains delayed at arrival'\n",
    "    ]\n",
    "    condition = (df[cols_num] >= 0).all(axis=1)\n",
    "    return df[condition]\n",
    "\n",
    "def fill_missed_value(df):\n",
    "    # cols num\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    for col in num_cols:\n",
    "        if df[col].dropna().empty:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    # cols str\n",
    "    str_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in str_cols:\n",
    "        df[col] = df[col].fillna(np.nan)\n",
    "    return df\n",
    "\n",
    "def date_formatting(df):\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m\", errors=\"coerce\")\n",
    "    df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m\")\n",
    "    return df\n",
    "\n",
    "def my_levenshtein(a, b, ratio=False, print_matrix=False, lowercase=False):\n",
    "    if type(a) is not str:\n",
    "        raise TypeError('First argument is not a string!')\n",
    "    if type(b) is not str:\n",
    "        raise TypeError('Second argument is not a string!')\n",
    "    if a == '':\n",
    "        return len(b)\n",
    "    if b == '':\n",
    "        return len(a)\n",
    "    if lowercase:\n",
    "        a = a.lower()\n",
    "        b = b.lower()\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    lev = np.zeros((n+1, m+1), dtype=np.uint16)\n",
    "    for i in range(n+1):\n",
    "        lev[i, 0] = i\n",
    "    for j in range(m+1):\n",
    "        lev[0, j] = j\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            insertion = lev[i-1, j] + 1\n",
    "            deletion = lev[i, j-1] + 1\n",
    "            substitution = lev[i-1, j-1] + (1 if a[i-1] != b[j-1] else 0)\n",
    "            lev[i, j] = min(insertion, deletion, substitution)\n",
    "    if print_matrix:\n",
    "        print(lev)\n",
    "    if ratio:\n",
    "        return (n + m - lev[n, m]) / (n + m)\n",
    "    else:\n",
    "        return lev[n, m]\n",
    "\n",
    "def missing_mandatory(df, mandatory_cols):\n",
    "    df_clean = df.copy()\n",
    "    for col in mandatory_cols:\n",
    "        if col in df_clean.columns:\n",
    "            idx_to_drop = df_clean[\n",
    "                df_clean[col].isna() | (df_clean[col].astype(str).str.lower() == 'nan')\n",
    "            ].index\n",
    "            df_clean = df_clean.drop(index=idx_to_drop)\n",
    "    return df_clean\n",
    "\n",
    "def find_closest_station(station_name, correct_stations, threshold=0.7):\n",
    "    station_name = station_name.upper()\n",
    "    best_match = station_name\n",
    "    best_score = 0\n",
    "    for correct_station in correct_stations:\n",
    "        score = my_levenshtein(station_name, correct_station.upper(), ratio=True)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = correct_station\n",
    "    return best_match if best_score >= threshold else station_name\n",
    "\n",
    "def find_closest_service(service_name, correct_services, threshold=0.7):\n",
    "    best_match = service_name\n",
    "    best_score = 0\n",
    "    for correct_service in correct_services:\n",
    "        score = my_levenshtein(service_name, correct_service, ratio=True)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = correct_service\n",
    "    return best_match if best_score >= threshold else service_name\n",
    "\n",
    "def correct_text_columns(df, station_columns, services_columns, station_list, services_list):\n",
    "    df_corrected = df.copy()\n",
    "    station_cache = {}\n",
    "    service_cache = {}\n",
    "\n",
    "    for col in station_columns:\n",
    "        if col in df_corrected.columns:\n",
    "            def get_corrected_station_name(station_name):\n",
    "                station_str = str(station_name).strip().upper()\n",
    "                if station_str in station_cache:\n",
    "                    return station_cache[station_str]\n",
    "                corrected = find_closest_station(station_str, station_list)\n",
    "                station_cache[station_str] = corrected\n",
    "                return corrected\n",
    "            df_corrected[col] = df_corrected[col].apply(get_corrected_station_name)\n",
    "\n",
    "    for col in services_columns:\n",
    "        if col in df_corrected.columns:\n",
    "            def get_corrected_service_name(service_name):\n",
    "                service_str = str(service_name).strip()\n",
    "                if service_str in service_cache:\n",
    "                    return service_cache[service_str]\n",
    "                corrected = find_closest_service(service_str, services_list)\n",
    "                service_cache[service_str] = corrected\n",
    "                return corrected\n",
    "            df_corrected[col] = df_corrected[col].apply(get_corrected_service_name)\n",
    "\n",
    "    return df_corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **📄 CSV File Handling Functions**\n",
    "\n",
    " `read_csv()`\n",
    "Reads a CSV file named `dataset.csv` using a semicolon (`;`) as the separator.\n",
    "Returns a `pandas` DataFrame containing the data from the file.\n",
    "\n",
    " `to_csv(df)`\n",
    "Writes a `pandas` DataFrame to a CSV file named `cleaned_dataset.csv` without including the index.\n",
    "Useful for saving cleaned or processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(df):\n",
    "    df.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "def read_csv():\n",
    "    return pd.read_csv(\"dataset.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **🧠 Data Processing Pipeline**\n",
    "\n",
    "`main()`\n",
    "\n",
    "Executes the complete SNCF data cleaning pipeline in the following order:\n",
    "\n",
    "1. **Reads** the raw dataset from `dataset.csv` using `read_csv()`.\n",
    "2. **Removes duplicate rows** with `remove_duplicates(df)`.\n",
    "3. **Filters out invalid negative values** using `remove_negative(df)`.\n",
    "4. **Corrects misspelled station and service names** via `correct_text_columns(...)`.\n",
    "5. **Fills missing values** with appropriate strategies using `fill_missed_value(df)`.\n",
    "6. **Formats date values** to the `'YYYY-MM'` format using `date_formatting(df)`.\n",
    "7. **Removes rows with missing mandatory fields** using `missing_mandatory(df, mandatory_cols)`.\n",
    "8. **Writes** the cleaned dataset to `cleaned_dataset.csv` with `to_csv(df)`.\n",
    "\n",
    "This function serves as the entry point of the script and runs automatically when the file is executed directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = read_csv()\n",
    "    df = remove_duplicates(df)\n",
    "    df = remove_negative(df)\n",
    "    df = correct_text_columns(df, station_cols, service_cols, correct_stations, correct_services)\n",
    "    df = fill_missed_value(df)\n",
    "    df = date_formatting(df)\n",
    "    df = missing_mandatory(df, mandatory_cols)\n",
    "    to_csv(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
