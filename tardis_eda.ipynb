{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center;\"><u>__EDA - Exploratory Data Analysis__<u></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ§° Dependencies**\n",
    "\n",
    " `import pandas as pd`\n",
    "Imports the **pandas** library, a powerful tool for data manipulation and analysis using DataFrames.\n",
    "\n",
    " `import numpy as np`\n",
    "Imports **NumPy**, a fundamental library for numerical computing in Python â€” often used for handling arrays, math operations, and missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš„ SNCF Data Cleaner - Railway Data Cleaning Toolkit ðŸ§¹\n",
    "\n",
    "*Your all-in-one solution for cleaning and preprocessing French railway data with style and precision.*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Overview\n",
    "\n",
    "This module offers a robust set of specialized functions to clean and prepare operational data from the French national railway system (SNCF). From removing duplicates to correcting \n",
    "station names, itâ€™s built to address real-world data quality issues commonly found in transportation datasets.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Core Functions\n",
    "\n",
    "### ðŸ§½ Basic Cleaning\n",
    "\n",
    "| Function                                | Description                                                                         |\n",
    "| --------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "| `remove_duplicates(df)`                 | Removes duplicate rows â€” because a train can't be in two places at once!            |\n",
    "| `remove_negative(df)`                   | Filters out impossible negative values from key metrics (e.g., -3 cancelled trains) |\n",
    "| `fill_missed_value(df)`                 | Smart imputation: uses median for numeric columns and preserves NaNs for text       |\n",
    "| `missing_mandatory(df, mandatory_cols)` | Drops rows with missing or invalid values in critical fields                        |\n",
    "\n",
    "### ðŸ“… Date Handling\n",
    "\n",
    "| Function              | Description                                               |\n",
    "| --------------------- | --------------------------------------------------------- |\n",
    "| `date_formatting(df)` | Converts and standardizes all dates to `'YYYY-MM'` format |\n",
    "\n",
    "### ðŸ·ï¸ Station and Service Name Correction\n",
    "\n",
    "| Function                                                                                 | Description                                                                                                       |\n",
    "| ---------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
    "| `correct_text_columns(df, station_columns, service_columns, station_list, service_list)` | Uses fuzzy matching (Levenshtein distance) to fix typos in station and service names, with caching for efficiency |\n",
    "#\n",
    "---\n",
    "\n",
    "## ðŸ›  Technical Details\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* Custom implementation of the Levenshtein distance for flexible fuzzy matching\n",
    "* Caching system to speed up repeated corrections\n",
    "* Configurable similarity thresholds (default: 0.7)\n",
    "\n",
    "**Predefined Station Names:**\n",
    "Includes over 50 French and international stations, such as:\n",
    "\n",
    "* **Major hubs**: Paris Montparnasse, Lyon Part-Dieu, Marseille St Charles\n",
    "* **Cross-border links**: Geneva, Barcelona, Zurich\n",
    "* **Regional stops**: Quimper, Tours, AngoulÃªme\n",
    "\n",
    "**Service Types:**\n",
    "\n",
    "* `National`\n",
    "* `International`\n",
    "#\n",
    "---\n",
    "#\n",
    "## âš™ï¸ Dependencies\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct_stations = [\n",
    "    \"BORDEAUX ST JEAN\", \"LA ROCHELLE VILLE\", \"PARIS MONTPARNASSE\", \"QUIMPER\", \"TOURS\",\n",
    "    \"ST PIERRE DES CORPS\", \"ST MALO\", \"NANTES\", \"PARIS EST\", \"STRASBOURG\", \"DUNKERQUE\",\n",
    "    \"LILLE\", \"PARIS VAUGIRARD\", \"RENNES\", \"TOURCOING\", \"CHAMBERY CHALLES LES EAUX\",\n",
    "    \"LYON PART DIEU\", \"MONTPELLIER\", \"MULHOUSE VILLE\", \"NICE VILLE\", \"PARIS LYON\",\n",
    "    \"BARCELONA\", \"GENEVE\", \"MADRID\", \"BREST\", \"POITIERS\", \"TOULOUSE MATABIAU\",\n",
    "    \"MARNE LA VALLEE\", \"MARSEILLE ST CHARLES\", \"FRANCFORT\", \"ANGOULEME\", \"METZ\",\n",
    "    \"PARIS NORD\", \"BELLEGARDE (AIN)\", \"MACON LOCHE\", \"PERPIGNAN\", \"DOUAI\",\n",
    "    \"VALENCE ALIXAN TGV\", \"LAUSANNE\", \"ANGERS SAINT LAUD\", \"STUTTGART\", \"LAVAL\",\n",
    "    \"NANCY\", \"BESANCON FRANCHE COMTE TGV\", \"GRENOBLE\", \"NIMES\", \"SAINT ETIENNE CHATEAUCREUX\",\n",
    "    \"ITALIE\", \"ZURICH\", \"VANNES\", \"ANNECY\", \"AVIGNON TGV\", \"LE MANS\", \"ARRAS\",\n",
    "    \"DIJON VILLE\", \"LE CREUSOT MONTCEAU MONTCHANIN\", \"REIMS\"\n",
    "]\n",
    "\n",
    "correct_services = [\"National\", \"International\"]\n",
    "\n",
    "mandatory_cols = [\"Date\", \"Service\", \"Departure station\", \"Arrival station\"]\n",
    "\n",
    "station_cols = [\"Departure station\", \"Arrival station\"]\n",
    "\n",
    "service_cols = [\"Service\"]\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop_duplicates(subset=mandatory_cols, keep='first')\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def remove_negative(df):\n",
    "    cols_num = [\n",
    "        'Average journey time',\n",
    "        'Number of scheduled trains',\n",
    "        'Number of cancelled trains',\n",
    "        'Number of trains delayed at departure',\n",
    "        'Number of trains delayed at arrival'\n",
    "    ]\n",
    "    condition = (df[cols_num] >= 0).all(axis=1)\n",
    "    return df[condition]\n",
    "\n",
    "def fill_missed_value(df):\n",
    "    # cols num\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    for col in num_cols:\n",
    "        if df[col].dropna().empty:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    # cols str\n",
    "    str_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in str_cols:\n",
    "        df[col] = df[col].fillna(np.nan)\n",
    "    return df\n",
    "\n",
    "def date_formatting(df):\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m\", errors=\"coerce\")\n",
    "    df[\"Date\"] = df[\"Date\"].dt.strftime(\"%Y-%m\")\n",
    "    return df\n",
    "\n",
    "def my_levenshtein(a, b, ratio=False, print_matrix=False, lowercase=False):\n",
    "    if type(a) is not str:\n",
    "        raise TypeError('First argument is not a string!')\n",
    "    if type(b) is not str:\n",
    "        raise TypeError('Second argument is not a string!')\n",
    "    if a == '':\n",
    "        return len(b)\n",
    "    if b == '':\n",
    "        return len(a)\n",
    "    if lowercase:\n",
    "        a = a.lower()\n",
    "        b = b.lower()\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "    lev = np.zeros((n+1, m+1), dtype=np.uint16)\n",
    "    for i in range(n+1):\n",
    "        lev[i, 0] = i\n",
    "    for j in range(m+1):\n",
    "        lev[0, j] = j\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            insertion = lev[i-1, j] + 1\n",
    "            deletion = lev[i, j-1] + 1\n",
    "            substitution = lev[i-1, j-1] + (1 if a[i-1] != b[j-1] else 0)\n",
    "            lev[i, j] = min(insertion, deletion, substitution)\n",
    "    if print_matrix:\n",
    "        print(lev)\n",
    "    if ratio:\n",
    "        return (n + m - lev[n, m]) / (n + m)\n",
    "    else:\n",
    "        return lev[n, m]\n",
    "\n",
    "def missing_mandatory(df, mandatory_cols):\n",
    "    df_clean = df.copy()\n",
    "    for col in mandatory_cols:\n",
    "        if col in df_clean.columns:\n",
    "            idx_to_drop = df_clean[\n",
    "                df_clean[col].isna() | (df_clean[col].astype(str).str.lower() == 'nan')\n",
    "            ].index\n",
    "            df_clean = df_clean.drop(index=idx_to_drop)\n",
    "    return df_clean\n",
    "\n",
    "def find_closest_station(station_name, correct_stations, threshold=0.7):\n",
    "    station_name = station_name.upper()\n",
    "    best_match = station_name\n",
    "    best_score = 0\n",
    "    for correct_station in correct_stations:\n",
    "        score = my_levenshtein(station_name, correct_station.upper(), ratio=True)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = correct_station\n",
    "    return best_match if best_score >= threshold else station_name\n",
    "\n",
    "def find_closest_service(service_name, correct_services, threshold=0.7):\n",
    "    best_match = service_name\n",
    "    best_score = 0\n",
    "    for correct_service in correct_services:\n",
    "        score = my_levenshtein(service_name, correct_service, ratio=True)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = correct_service\n",
    "    return best_match if best_score >= threshold else service_name\n",
    "\n",
    "def correct_text_columns(df, station_columns, services_columns, station_list, services_list):\n",
    "    df_corrected = df.copy()\n",
    "    station_cache = {}\n",
    "    service_cache = {}\n",
    "\n",
    "    for col in station_columns:\n",
    "        if col in df_corrected.columns:\n",
    "            def get_corrected_station_name(station_name):\n",
    "                station_str = str(station_name).strip().upper()\n",
    "                if station_str in station_cache:\n",
    "                    return station_cache[station_str]\n",
    "                corrected = find_closest_station(station_str, station_list)\n",
    "                station_cache[station_str] = corrected\n",
    "                return corrected\n",
    "            df_corrected[col] = df_corrected[col].apply(get_corrected_station_name)\n",
    "\n",
    "    for col in services_columns:\n",
    "        if col in df_corrected.columns:\n",
    "            def get_corrected_service_name(service_name):\n",
    "                service_str = str(service_name).strip()\n",
    "                if service_str in service_cache:\n",
    "                    return service_cache[service_str]\n",
    "                corrected = find_closest_service(service_str, services_list)\n",
    "                service_cache[service_str] = corrected\n",
    "                return corrected\n",
    "            df_corrected[col] = df_corrected[col].apply(get_corrected_service_name)\n",
    "\n",
    "    return df_corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ“„ CSV File Handling Functions**\n",
    "\n",
    " `read_csv()`\n",
    "Reads a CSV file named `dataset.csv` using a semicolon (`;`) as the separator.\n",
    "Returns a `pandas` DataFrame containing the data from the file.\n",
    "\n",
    " `to_csv(df)`\n",
    "Writes a `pandas` DataFrame to a CSV file named `cleaned_dataset.csv` without including the index.\n",
    "Useful for saving cleaned or processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(df):\n",
    "    df.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "def read_csv():\n",
    "    return pd.read_csv(\"dataset.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ§  Data Processing Pipeline**\n",
    "\n",
    "`main()`\n",
    "\n",
    "Executes the complete SNCF data cleaning pipeline in the following order:\n",
    "\n",
    "1. **Reads** the raw dataset from `dataset.csv` using `read_csv()`.\n",
    "2. **Removes duplicate rows** with `remove_duplicates(df)`.\n",
    "3. **Filters out invalid negative values** using `remove_negative(df)`.\n",
    "4. **Corrects misspelled station and service names** via `correct_text_columns(...)`.\n",
    "5. **Fills missing values** with appropriate strategies using `fill_missed_value(df)`.\n",
    "6. **Formats date values** to the `'YYYY-MM'` format using `date_formatting(df)`.\n",
    "7. **Removes rows with missing mandatory fields** using `missing_mandatory(df, mandatory_cols)`.\n",
    "8. **Writes** the cleaned dataset to `cleaned_dataset.csv` with `to_csv(df)`.\n",
    "\n",
    "This function serves as the entry point of the script and runs automatically when the file is executed directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = read_csv()\n",
    "    df = remove_duplicates(df)\n",
    "    df = remove_negative(df)\n",
    "    df = correct_text_columns(df, station_cols, service_cols, correct_stations, correct_services)\n",
    "    df = fill_missed_value(df)\n",
    "    df = date_formatting(df)\n",
    "    df = missing_mandatory(df, mandatory_cols)\n",
    "    to_csv(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
